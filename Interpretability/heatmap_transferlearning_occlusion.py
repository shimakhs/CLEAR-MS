# -*- coding: utf-8 -*-
"""Heatmap_TransferLearning_occlusion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KV3xR22UW3VvyGkINHaDzgj2Z5GFBdtb
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/Colab Notebooks/Codes for Deep learning paper- khordad 1402'

pip install sporco

pip install imgaug

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import cv2
from sporco import plot
from sklearn.model_selection import train_test_split
import keras
from matplotlib import pyplot as plt
import numpy as np
# %matplotlib inline
from keras.models import Model
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import LeakyReLU
from keras.layers import Input,Dense,Flatten,Conv2D,MaxPooling2D,UpSampling2D,Dropout,AveragePooling2D
from tensorflow.keras.layers import BatchNormalization
from keras.models import Model,Sequential
from keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import  RMSprop,Adam,SGD,Adadelta,Adagrad,Adamax,Nadam,Ftrl
from keras import regularizers
from sklearn.model_selection import train_test_split
from keras.layers import LeakyReLU
from sklearn.model_selection import StratifiedKFold
from sklearn import metrics
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,balanced_accuracy_score

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import sys, os
import pickle
import seaborn as sns
import pandas as pd
import imgaug as ia
import imgaug.augmenters as iaa
import math
np.random.seed(1234)

# Getting back the objects:
with open('ScanPosition' + '.pkl', 'rb') as f:
   sp = pickle.load(f)
with open('XLayersBoundaryMap' + '.pkl', 'rb') as f:
   X = pickle.load(f)
with open('HMlabels' + '.pkl', 'rb') as f:
   Y  = pickle.load(f)

### flip all boundaries to be like right eye
for i in range(len(sp)):
  if sp[i]:
    X[i] = X[i][:,:,::-1,:]

dim1=224
dim2=224

def plot_img(img,name):

    fig = plot.figure(figsize=(14, 14))
    plot.imview(img, title=name, fig=fig)
    fig.show()

    return

def preprocess_data(X,Y):
    img=np.array([])
    dataset=np.zeros((len(X),dim1,dim2,9))
    for j in range(len(X)):
        img0=X[j]
        img=img0.squeeze()
        img=cv2.resize(img,(dim2,dim1))
        num=img.shape[2]
        def_img=np.zeros((img.shape))

        for k in range(0,num-1):
            def_img[:,:,k]=img[:,:,k+1]-img[:,:,k]
            #plot_img(def_img[:,:,k], name='img'+str(j)+'_def_layer'+str(k)+'Y'+str(Y[j]))


        def_img[:,:,num-1]=img[:,:,num-1]-img[:,:,0]
        #plot_img(def_img[:,:,num-1], name='img'+str(j)+'_def_layer'+str(8))



        dataset[j,:,:,:]=def_img
    return dataset

def final_dataset(dataset,Y,num_chanel,ch):
    new_dataset=np.zeros((len(dataset),dataset[0].shape[0],dataset[0].shape[1],len(ch)))

    for k in range(len(dataset)):

        img=dataset[k,:,:,:]
        new_img=np.zeros((img.shape[0],img.shape[1],num_chanel))

        for j in range(len(ch)):
            #new_img[:,:,j]=(img[:,:,ch[j]]/np.max(img[:,:,ch[j]])).astype('float32')
            I=img[:,:,ch[j]]
            new_img[:,:,j]=((I-np.min(I))/(np.max(I)-np.min(I))).astype('float32')

        new_dataset[k,:,:,:]=new_img


    Y=np.array(Y).squeeze()
    print('new_dataset:',new_dataset.shape)

    return new_dataset ,Y

ch=[0,1,2] # layer number
# ch=[0,1]
num_chanel=len(ch) # number of chanel
dataset=preprocess_data(X,Y)
print('dataset.shape:',dataset.shape)

new_dataset ,Y=final_dataset(dataset,Y,num_chanel,ch)
print('Y shape:',Y.shape)

unique, counts = np.unique(Y, return_counts=True)
label=dict(zip(unique, counts))
print('label:',label)

import tensorflow as tf
from tensorflow.keras.applications import VGG16,ResNet152V2,Xception,VGG19,ResNet50,ResNet101,ResNet101V2
def CNN(input):
   base_model =tf.keras.applications.ResNet152V2(include_top=False, weights="imagenet", input_tensor=None, input_shape=(dim1,dim2,num_chanel), pooling=None, classes=1000, classifier_activation="softmax")
   base_model.trainable = False
   base_model.summary()

   x = base_model(input, training=False)
   x=keras.layers.Flatten()(x)
   x = keras.layers.Dropout(0.3)(x)
   x=keras.layers.Dense(1024, activation='relu')(x)
   x=keras.layers.Dense(512, activation='relu')(x)
   x=keras.layers.Dense(256, activation='relu')(x)
   x=keras.layers.Dense(128, activation='relu')(x)
   x=keras.layers.Dense(2, activation='softmax')(x)
   return x

input=Input(shape=(dim1,dim2,num_chanel))
output=CNN(input)
model = Model(inputs=input, outputs=output)
model.summary()

def CNN_model():
   inputs = keras.Input(shape=(dim1,dim2,num_chanel))
   base_model =tf.keras.applications.ResNet152V2(include_top=False, weights="imagenet", input_tensor=inputs, input_shape=(dim1,dim2,num_chanel))
   base_model.trainable = False ## Not trainable weights
   x = base_model(inputs)
   x=keras.layers.Flatten()(x)
   x = keras.layers.Dropout(0.3)(x)
   x=keras.layers.Dense(1024, activation='relu')(x)
   x=keras.layers.Dense(512, activation='relu')(x)
   x=keras.layers.Dense(256, activation='relu')(x)
   x=keras.layers.Dense(128, activation='relu')(x)
   x=keras.layers.Dense(2, activation='softmax')(x)

   return Model(inputs,x)

def classify_model():
    inputs=keras.Input(shape=(dim1,dim2,num_chanel))
    conv_model=CNN_model()
    outputs=conv_model(inputs)
    full_model=Model(inputs=inputs,outputs=outputs)
    full_model.summary()
    # full_model.compile(loss="binary_crossentropy", optimizer=SGD(),metrics=['accuracy'])
    full_model.compile(loss="binary_crossentropy", optimizer=Adam(),metrics=['accuracy'])
    # full_model.compile(loss="categorical_crossentropy", optimizer=Adam(),metrics=['accuracy'])


    return full_model

def plot_loss(classify,itr):
    loss = classify.history['loss']
    val_loss = classify.history['val_loss']
    epochs = range(itr)
    plt.figure()
    plt.plot(epochs, loss, 'r', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()
    plt.show()

    loss = classify.history['accuracy']
    val_loss = classify.history['val_accuracy']
    epochs = range(itr)
    plt.figure()
    plt.plot(epochs, loss, 'r', label='Training acc')
    plt.plot(epochs, val_loss, 'b', label='Validation acc')
    plt.title('Training and validation acc')
    plt.legend()
    plt.show()

# Confusion Matrix
import itertools
def plot_confusion_matrix(cm,
                          target_names,
                          title='',
                          #cmap=plt.cm.gist_yarg,
                          cmap='Blues',
                          normalize=True):

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if normalize:
      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
      print("Normalized confusion matrix")
    else:
        print('Confusion matrix')

    plt.style.use('seaborn-ticks')
    plt.figure(figsize=(9,6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    #plt.colorbar()
    tick_marks = np.arange(len(target_names))
    plt.xticks(tick_marks, target_names, rotation=0)
    plt.yticks(tick_marks, target_names)




    fmt = '.3f' if normalize else 'd'


    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize and cm[i, j] > 0:
            plt.text(j, i, format(cm[i, j],fmt),
                     horizontalalignment="center",
                     verticalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        elif normalize == False and cm[i, j] > 0:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     verticalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True labels')
    plt.xlabel('\nPredicted labels')

import tensorflow as tf
num_fold=5
balanced_acc_arr=[]
acc_arr=[]
skf = StratifiedKFold(n_splits=num_fold,shuffle=True,random_state=52)
skf.get_n_splits(new_dataset, Y)
yt=[]
yp=[]
fold_counter=0

for train_index, test_index in skf.split(new_dataset, Y):
      print('train_index:',len(train_index))
      print('test_ix:', len(test_index))
      fold_counter=fold_counter+1
      print('*****************fold_counter*********************',fold_counter)
      train_index=(np.array(train_index)).astype('uint8')
      test_index=(np.array(test_index)).astype('uint8')

      x_train  ,  X_test = new_dataset[train_index] , new_dataset[test_index]
      y_train, y_test = Y[train_index] , Y[test_index]

      # define and call model for classify images :
      model=classify_model()
      ch = keras.callbacks.ModelCheckpoint( '/content/drive/MyDrive/dr kafieh/model_transfer.h5',monitor= "val_accuracy",save_weights_only=False,save_best_only=True,mode='max')
      callbacks = [ch]
      # agument images:

      from tensorflow.keras.utils import to_categorical
      #one_hot_train_label = to_categorical(new_y_train)

      one_hot_train_label = to_categorical(y_train)
      one_hot_test_label=to_categorical(y_test)

      #agmunt data:
      from keras.preprocessing.image import ImageDataGenerator
      datagen = ImageDataGenerator(
          horizontal_flip=True,
          vertical_flip=True,
          rotation_range=20,
          data_format='channels_last',
          fill_mode='nearest')#


      datagen.fit(x_train)
      train_iterator = datagen.flow(x_train,one_hot_train_label ,batch_size=12,shuffle=True)#12
      print('Batches train=%d' % (len(train_iterator)))

      batch_x,batch_y = next(train_iterator)
      print('batch_x:',batch_x.shape)
      print('batch_y:',batch_y.shape)

      itr_epochs=200
      classify = model.fit( train_iterator ,epochs=itr_epochs,verbose=1,shuffle=True,validation_data=(X_test,one_hot_test_label),batch_size=80,callbacks=callbacks)

      plot_loss(classify,itr_epochs)

      # evalute model :
      model_classification = keras.models.load_model( '/content/drive/MyDrive/dr kafieh/model_transfer.h5')
      y_pred = np.argmax(model_classification.predict(X_test), axis = 1)
      print('classes prediction:',y_pred)

      cm1 = metrics.confusion_matrix(np.array(y_test), np.array(y_pred))
      total1=sum(sum(cm1))
      Accuracy = (cm1[0,0]+cm1[1,1])/total1
      Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])
      Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])

      acc_arr.append([Accuracy])

      gmean = np.sqrt(Sensitivity * Specificity)
      balanced_accuracy = balanced_accuracy_score(np.array(y_test), np.array(y_pred))
      balanced_acc_arr.append([balanced_accuracy])

      print ("Accuracy: %.4f "%Accuracy)
      print ("Specificity: %.4f " %Specificity)
      print ("Sensitivity: %.4f "%Sensitivity)
      print ("gmean: %.4f"%gmean)
      print ("balanced_accuracy: %.4f"%balanced_accuracy)
      print("******************************************************")
      print("******************************************************")


      print(classification_report(np.array(y_test),np.array(y_pred),digits=4))
      print("******************************************************")
      print("******************************************************")

      cm = confusion_matrix(np.array(y_test),np.array(y_pred))
      np.set_printoptions(precision=15)
      plot_confusion_matrix(cm = cm, normalize = False, target_names = ["HC","MS"])
      plt.show()
      print("******************************************************")
      print("******************************************************")
      yt.append(np.array(y_test).flatten())
      yp.append(np.array(y_pred).flatten())

print('avg_acc:',np.mean(np.array(acc_arr)))
print('avg_bacc:',np.mean(np.array(balanced_acc_arr)))

yy =[]
pp = []
for i in range(len(yt)):
  for j in range(len(yt[i])):
    yy.append(yt[i][j])
    pp.append(yp[i][j])

cm = confusion_matrix(np.array(yy),np.array(pp))
np.set_printoptions(precision=15)
plot_confusion_matrix(cm = cm, normalize = True, target_names = ["HC","MS"])
# plt.grid('off')
plt.legend(prop={'size': 27})
#plt.savefig('/content/cm_denseNet121.png', dpi = 200, facecolor='w', edgecolor='w', orientation='landscape', papertype=None, format=None, transparent=False, bbox_inches='tight', pad_inches=None, frameon=None)
plt.show()

from sklearn import metrics
cm1 = metrics.confusion_matrix(np.array(yy), np.array(pp))
total1=sum(sum(cm1))
Accuracy = (cm1[0,0]+cm1[1,1])/total1
Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])
Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])

gmean = np.sqrt(Sensitivity * Specificity)
balanced_accuracy = balanced_accuracy_score(np.array(yy), np.array(pp))

print ("Accuracy: %.4f "%Accuracy)
print ("Specificity: %.4f " %Specificity)
print ("Sensitivity: %.4f "%Sensitivity)
print ("gmean: %.4f"%gmean)
print ("balanced_accuracy: %.4f"%balanced_accuracy)

print(classification_report(np.array(yy),np.array(pp),digits=4))

fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred)

plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()
print('roc_auc_score for CNN: ', metrics.roc_auc_score(y_test, y_pred))

y_test

x1 = X_test.copy()
x2 = np.delete(x1,0,axis=0)
y1 = y_test.copy()
y2 = np.delete(y1,0,axis=0)
print(x2.shape)
y2

x3 = np.delete(x2,1,axis=0)
y3 = np.delete(y2,1,axis=0)
print(x3.shape)
y3

x4 = np.delete(x3,4,axis=0)
y4 = np.delete(y3,4,axis=0)
print(x4.shape)
y4

x5 = np.delete(x4,4,axis=0)
y5 = np.delete(y4,4,axis=0)
print(x5.shape)
y5

x6 = np.delete(x5,4,axis=0)
y6 = np.delete(y5,4,axis=0)
print(x6.shape)
y6

x7 = np.delete(x6,4,axis=0)
y7 = np.delete(y6,4,axis=0)
print(x7.shape)
y7

x8 = np.delete(x7,4,axis=0)
y8 = np.delete(y7,4,axis=0)
print(x8.shape)
y8

from keras.utils import to_categorical
encoded = to_categorical(y8)
encoded

heat_acc = np.zeros((185,185))

for k in range(0,185):
    for j in range(0,185):
       x9 = x8.copy()
       #for i in range(0,184):
          #for l in range(0,184):
       x9[:,k:k+40,j:j+40,1] = 0
       #y_pred = model_classification.predict(X_test_zero)# Evaluate our model
       y_pred = model_classification.predict(x9)# Evaluate our model#### just MS data is test set

       y_pred[y_pred>.5] = 1
       y_pred[y_pred<.5] = 0
       #accuracy = (metrics.accuracy_score(y_test, y_pred))
       accuracy = (metrics.accuracy_score(encoded, y_pred))

       heat_acc[k,j] = accuracy

import matplotlib.pyplot as plt
import seaborn as sns

import matplotlib.pyplot as plt
import seaborn as sns
ax = sns.heatmap(heat_acc)